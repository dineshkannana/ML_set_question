{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "163c380c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature1  Feature2\n",
      "0        10       5.5\n",
      "1        20       6.7\n",
      "2        30       8.9\n"
     ]
    }
   ],
   "source": [
    "#1.Debug the given code\n",
    "#import pandas as pd\n",
    "\n",
    "#data = {'Feature1': ['10', '20', 'Thirty'],  # 'Thirty' is not a valid number\n",
    "       # 'Feature2': [5.5, 6.7, 8.9]}\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "#df['Feature1'] = df['Feature1'].astype(int)  # Error: Cannot convert 'Thirty' to int\n",
    "\n",
    "#print(df)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = {'Feature1': ['10', '20', '30'], # Corrected 'Thirty' to '30'\n",
    "        'Feature2': [5.5, 6.7, 8.9]}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df['Feature1'] = df['Feature1'].astype(int)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75ed407d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B\n",
      "0  1.0  4.0\n",
      "1  2.0  5.0\n",
      "2  1.5  6.0\n"
     ]
    }
   ],
   "source": [
    "#2.\n",
    "#import pandas as pd\n",
    "\n",
    "#data = {'A': [1, 2, None],  # Missing value\n",
    " #       'B': [4, None, 6]}  # Missing value\n",
    "\n",
    "#df = pd.DataFrame(data)\n",
    "#mean_value = df.mean()\n",
    "#df.fillna(mean_value)  # Error: fillna() does not modify in place\n",
    "\n",
    "#print(df)\n",
    "import pandas as pd\n",
    "\n",
    "data = {'A': [1, 2, None],  # Missing value\n",
    "        'B': [4, None, 6]}  # Missing value\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "mean_value = df.mean()\n",
    "\n",
    "df.fillna(mean_value, inplace=True)   #  modifies df directly\n",
    "\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65cb6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: [2.]\n",
      "Intercept: 0.0\n"
     ]
    }
   ],
   "source": [
    "#3.from sklearn.linear_model import LinearRegression\n",
    "#import numpy as np\n",
    "\n",
    "#X = np.array([1, 2, 3, 4, 5])  # Error: X should be 2D\n",
    "#y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "#model = LinearRegression()\n",
    "#model.fit(X, y)\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Reshape X to make it 2D\n",
    "X = np.array([1, 2, 3, 4, 5]).reshape(-1, 1)\n",
    "y = np.array([2, 4, 6, 8, 10])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "print(\"Coefficient:\", model.coef_)\n",
    "print(\"Intercept:\", model.intercept_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b60f10de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356]\n",
      " [-0.70710678]\n",
      " [ 0.        ]\n",
      " [ 0.70710678]\n",
      " [ 1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "#4.\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "#import numpy as np\n",
    "\n",
    "#data = np.array([10, 20, 30, 40, 50])  # Error: Should be 2D\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "#print(scaled_data)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "data = np.array([10, 20, 30, 40, 50]).reshape(-1, 1)  # Error: Should be 2D\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da46280a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['no' 'yes']\n",
      "Predictions: [1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#5.\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#X = [[1, 2], [3, 4], [5, 6]]\n",
    "#y = ['yes', 'no', 'yes']  # Error: Labels should be numeric\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#model.fit(X, y)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = [[1, 2], [3, 4], [5, 6]]\n",
    "y = ['yes', 'no', 'yes']\n",
    "\n",
    "#  Convert 'yes'/'no' to 1/0\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y_encoded)\n",
    "\n",
    "print(\"Classes:\", encoder.classes_)   # ['no' 'yes']\n",
    "print(\"Predictions:\", model.predict(X))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6845ab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]]\n",
      "[array(['A', 'B', 'C'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "#6.import pandas as pd\n",
    "#from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "#df = pd.DataFrame({'Category': ['A', 'B', 'C', 'A']})\n",
    "\n",
    "#encoder = OneHotEncoder()\n",
    "#encoded = encoder.fit_transform(df['Category'])   # Error: Data should be reshaped\n",
    "#print(encoded)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.DataFrame({'Category': ['A', 'B', 'C', 'A']})\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "encoded = encoder.fit_transform(df[['Category']])   # FIXED\n",
    "\n",
    "print(encoded.toarray())      # toarray() to see 0/1 encoding\n",
    "print(encoder.categories_)    # see which categories were encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4e1665b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: [[7, 8], [1, 2], [5, 6]]\n",
      "X_test: [[3, 4]]\n",
      "y_train: [1, 0, 0]\n",
      "y_test: [1]\n"
     ]
    }
   ],
   "source": [
    "#6.\n",
    "#from sklearn.model_selection import train_test_split\n",
    "\n",
    "#X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "#y = [0, 1, 0]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = [[1, 2], [3, 4], [5, 6], [7, 8]]\n",
    "y = [0, 1, 0, 1]  #  Now y has 4 labels for 4 samples\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"X_train:\", X_train)\n",
    "print(\"X_test:\", X_test)\n",
    "print(\"y_train:\", y_train)\n",
    "print(\"y_test:\", y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9a8ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded classes: ['no' 'yes']\n",
      "Model predictions (encoded): [1 1 1]\n",
      "Predictions (original labels): ['yes' 'yes' 'yes']\n"
     ]
    }
   ],
   "source": [
    "#7.from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "#y_train = [\"yes\", \"no\", \"yes\"]  # Error: LogisticRegression expects numerical labels\n",
    "\n",
    "#model = LogisticRegression()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "y_train = [\"yes\", \"no\", \"yes\"]\n",
    "\n",
    "#  Step 1: Encode labels\n",
    "encoder = LabelEncoder()\n",
    "y_train_encoded = encoder.fit_transform(y_train)  # \"no\"→0, \"yes\"→1\n",
    "\n",
    "#  Step 2: Fit model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"Encoded classes:\", encoder.classes_)        # ['no' 'yes']\n",
    "print(\"Model predictions (encoded):\", model.predict(X_train))\n",
    "print(\"Predictions (original labels):\", encoder.inverse_transform(model.predict(X_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee13984b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train after dropping NaNs:\n",
      " [[1. 2.]\n",
      " [5. 6.]]\n",
      "y_train after dropping NaNs:\n",
      " [10 30]\n",
      "Model coefficients: [2.5 2.5]\n",
      "Model intercept: 2.500000000000007\n"
     ]
    }
   ],
   "source": [
    "#8.\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating a dataset with missing values\n",
    "#X_train = np.array([[1, 2], [3, np.nan], [5, 6]])\n",
    "#y_train = np.array([10, 20, 30])\n",
    "\n",
    "#model = LinearRegression()\n",
    "#model.fit(X_train, y_train)  \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Creating a dataset with missing values\n",
    "X_train_raw = np.array([[1, 2], [3, np.nan], [5, 6]])\n",
    "y_train_raw = np.array([10, 20, 30])\n",
    "\n",
    "# Combine X and y into a DataFrame to easily drop rows\n",
    "df = pd.DataFrame(X_train_raw)\n",
    "df['target'] = y_train_raw\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_cleaned = df.dropna()\n",
    "\n",
    "X_train_cleaned = df_cleaned.drop('target', axis=1).values\n",
    "y_train_cleaned = df_cleaned['target'].values\n",
    "\n",
    "if X_train_cleaned.shape[0] > 0: # Check if there's data left after dropping NaNs\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train_cleaned, y_train_cleaned)\n",
    "    print(\"X_train after dropping NaNs:\\n\", X_train_cleaned)\n",
    "    print(\"y_train after dropping NaNs:\\n\", y_train_cleaned)\n",
    "    print(\"Model coefficients:\", model.coef_)\n",
    "    print(\"Model intercept:\", model.intercept_)\n",
    "else:\n",
    "    print(\"No data remaining after dropping rows with missing values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29fdd8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['ham' 'spam']\n",
      "Prediction for [4,5]: ['ham']\n"
     ]
    }
   ],
   "source": [
    "#9.\n",
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "#y_train = [\"spam\", \"ham\", \"spam\"]  # Error: String labels not allowed\n",
    "\n",
    "#model = DecisionTreeClassifier()\n",
    "#model.fit(X_train, y_train)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "X_train = [[1, 2], [3, 4], [5, 6]]\n",
    "y_train = [\"spam\", \"ham\", \"spam\"]   #  String labels are fine\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"Classes:\", model.classes_)\n",
    "print(\"Prediction for [4,5]:\", model.predict([[4, 5]]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4057ff6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n"
     ]
    }
   ],
   "source": [
    "#10.\n",
    "#from sklearn.svm import SVC\n",
    "\n",
    "#X_train = [[1, 100], [2, 200], [3, 300]]\n",
    "#y_train = [0, 1, 0]\n",
    "\n",
    "#model = SVC()\n",
    "#model.fit(X_train, y_train)\n",
    "#print(model.predict([[1, 150]]))  # Unreliable output due to large-scale difference\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Training data\n",
    "X_train = [[1, 100], [2, 200], [3, 300]]\n",
    "y_train = [0, 1, 0]\n",
    "\n",
    "# 1. Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "#  2. Train the model on scaled data\n",
    "model = SVC()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 3. Scale the test data before predicting\n",
    "test_point = scaler.transform([[1, 150]])\n",
    "print(\"Prediction:\", model.predict(test_point))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045c1234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
